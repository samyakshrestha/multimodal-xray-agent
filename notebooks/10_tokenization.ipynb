{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u49INj7fNIUB"
   },
   "source": [
    "## Step 1: Mounting Google Drive and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15290,
     "status": "ok",
     "timestamp": 1749807600749,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "a5IP1h8xM_dr",
    "outputId": "9a2f91d2-0acf-4d96-a230-3e29944e7e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive/multimodal-xray-agent\n",
      "app\t      deployment  models\t  README.md\t    src\n",
      "chexpert.zip  LICENSE\t  notebooks\t  requirements.txt\n",
      "data\t      logs\t  PROJECT_LOG.md  scripts\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/multimodal-xray-agent\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-AP1m0f7Tan6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, DatasetDict, load_from_disk, Dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "b611dc76d67a4b6c9c9adf318621be3d",
      "3041e7a1b37c438ea8815317dac6788d",
      "1bbb6a1a128c4a3596d7b0763162757f",
      "4f977cac739c4eb189f6beee2a6d2844",
      "72e19592ce47425ea54055a278fecb6a",
      "efdc2971e12842e29eefa664f62afc24",
      "6329ddd936d642fdbd5d238af034fe08",
      "1cd90dd0f4354bf3932e31ee27fd10df",
      "683f0c033d604b78b67394f8f85ba955",
      "ce05f69c9b2c485790468fa924783593",
      "90f984aecd1d46be94e5678ec31b6e4f",
      "ba5e0a97f860465aa2508a3e8cc90eb7",
      "498481cba4fc477ebcfc2aeb1629fd08",
      "4e6a3131d6c84742ab0c5dd54a4d81cf",
      "ffba8a2ca8dc4003a139796d8445d24d",
      "7b7f7db5a16847f990c70705e90f502b",
      "4648fd16d24f47ff8096e83de0cd0f1f",
      "8fbaef66e459443980ce97cf09763214",
      "e1107bc01ea34838b0564dac026ddeeb",
      "d9549bdb215f4a67b78d51956ce20387"
     ]
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1749807613866,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "C5azyPSX-CAK",
    "outputId": "877c6e74-c711-4951-bcd5-209384fc51de"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b611dc76d67a4b6c9c9adf318621be3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riaLSQlrTRmC"
   },
   "source": [
    "## Step 2: Loading QA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0H5-KpE2QvP"
   },
   "outputs": [],
   "source": [
    "# Copy file from GDrive to Colab local runtime\n",
    "!cp /content/drive/MyDrive/multimodal-xray-agent/data/qapairs/top_700_qa_pairs.jsonl /content/top_700_qa_pairs.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4Ie70skIwVM"
   },
   "outputs": [],
   "source": [
    "# Load the data manually\n",
    "with open(\"/content/top_700_qa_pairs.jsonl\", \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKt07APYI4_Q"
   },
   "outputs": [],
   "source": [
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1749807624871,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "K9guODI3JBcb",
    "outputId": "117682fc-c051-484c-e4b7-efeb367e7a78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRySNPR7UGh0"
   },
   "source": [
    "## Step 3: Formatting Dataset for Supervised Fine-Tuning\n",
    "\n",
    "In this step, we format each QA pair into an instruction-following format expected by our model during training. The `format_example()` function wraps the question and answer into a structured prompt using markdown-style headings `(### Question: / ### Answer:)`, which helps the model learn the instruction-response format more reliably.\n",
    "\n",
    "In essence, this function takes a QA pair and transforms it into a single string where the question and answer are clearly labeled with headings and separated by newlines. This structured format helps the language model learn the relationship between questions and answers more effectively during the fine-tuning process.\n",
    "\n",
    "We then use the `.map()` function to apply this transformation to the entire dataset, removing the original \"question\" and \"answer\" fields and keeping only the unified \"text\" field for training.\n",
    "\n",
    "This is the final format that will be tokenized and fed into the model for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUfiAnoPUIxQ"
   },
   "outputs": [],
   "source": [
    "# Format each QA pair into an instruction-following prompt\n",
    "def format_example(example):\n",
    "    return {\n",
    "        \"text\": f\"### Question:\\n{example['question']}\\n\\n### Answer:\\n{example['answer']}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c0e1edffb13d4dfdb6940b0e055ad6d0",
      "75d3e2aedb204d63be349b0b7e70c33a",
      "9441c9a7566f45f89fe6af630b394d22",
      "4a32d8877b60439399ea65af4146ec20",
      "c9ce8d5bbf0445ed8907725a76e6a4da",
      "1fb0cb36e1e249f498a46987e9a5a72e",
      "e3782973021540f69f31409f271729fe",
      "a4b3fc9211394b5896b5a64399d782b2",
      "2ec9f0c09fcc4a53901f2a3c01b18549",
      "587740e586774f15975fdd391f159934",
      "b61fba081a9d45508eeafa7175efb330"
     ]
    },
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1749807627948,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "98DKz0fUUOJl",
    "outputId": "483ce77d-2627-44bd-e138-6928c1cd1f40"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e1edffb13d4dfdb6940b0e055ad6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply formatting to all samples in the dataset\n",
    "formatted_dataset = dataset.map(format_example, remove_columns=[\"uuid\", \"question\", \"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1749807629350,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "c-J3BTbaUUQO",
    "outputId": "fbd324dd-5d4b-4e8c-8056-8c284a6f7d33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '### Question:\\nIs there any evidence of disease in the X-ray?\\n\\n### Answer:\\n1. Severe emphysema. 2. Irregular, pleural-parenchymal opacity in left upper lobe. This may irregular pleural-parenchymal scarring, however, recommend comparison with more remote outside imaging, if available to determine long-term stability. If none are available, recommend short-term [REDACTED] in 3 to 4 months. Evaluation of coronal and sagittal reformatted images from the outside study would also be helpful. These were not [REDACTED] available at the outside institution. Malignancy cannot be confidently excluded on the available images'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1749807630635,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "pJSj4NaWKME_",
    "outputId": "f32e8316-dc2f-45ca-efb1-5a520c3a28c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_dataset.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qecXSGlEUiFN"
   },
   "source": [
    "## Step 4:  Loading the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahn7upF7Ujig"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZZ0MtOJqJ8V"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1749807655073,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "hmq8ng3oqIS2",
    "outputId": "31ff7fa2-247d-449f-9f82-c7b9725d48c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1749807747421,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "b1U0nUc6Unvo",
    "outputId": "61ffc5c8-1bb3-47fe-8114-cb5717a8308c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': '<pad>'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QxUzu9kU9KK"
   },
   "source": [
    "## Step 5: Tokenizing the Dataset for Causal Language Modeling\n",
    "\n",
    "We now tokenize the dataset using the LLaMA tokenizer. Each example is formatted in the style:\n",
    "\n",
    "```\n",
    "### Question:\n",
    "{question text}\n",
    "\n",
    "### Answer:\n",
    "{answer text}\n",
    "```\n",
    "\n",
    "During tokenization, each example is converted into three key fields:\n",
    "\n",
    "- **input_ids**: Token IDs representing the full prompt (`question + answer`) to be fed into the model.\n",
    "- **attention_mask**: Binary vector indicating which tokens are real (1) vs. padding (0).\n",
    "- **labels**: Target tokens that the model should try to predict during training.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why Label Masking?\n",
    "\n",
    "In causal language modeling (CLM), the model learns by **predicting the next token**, one step at a time. To train the model to *only* learn to generate the **answer** (not the question or prompt), we **mask the prompt portion** of the labels using `-100`. This tells the loss function to **ignore these tokens** during gradient computation.\n",
    "\n",
    "The logic is:\n",
    "\n",
    "```python\n",
    "labels = [-100] * len(prompt_ids) + result[\"input_ids\"][len(prompt_ids):]\n",
    "```\n",
    "\n",
    "- `-100` is the special ignored index in PyTorch loss functions.\n",
    "- The answer portion (after the prompt) remains unmasked and is used for learning.\n",
    "- We truncate or pad the label sequence to `max_length = 512` for stability.\n",
    "\n",
    "---\n",
    "\n",
    "#### Tokenization Config\n",
    "\n",
    "```python\n",
    "tokenizer(\n",
    "    example[\"text\"],\n",
    "    truncation=True,         # Cut off long sequences safely\n",
    "    padding=\"max_length\",    # Pad all to uniform length\n",
    "    max_length=512           # Max allowed length (safe for 3B models)\n",
    ")\n",
    "```\n",
    "\n",
    "We chose `max_length = 512` to ensure future compatibility with longer inference prompts and outputs (e.g., definitions, expanded context). This also keeps GPU memory usage manageable and prevents truncating informative answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYv3lHi3U8lL"
   },
   "outputs": [],
   "source": [
    "def tokenize(example):\n",
    "    # Compute prompt length so we know what to mask\n",
    "    prompt_split = example[\"text\"].split(\"### Answer:\\n\")  # Split text at answer section\n",
    "    prompt_ids = tokenizer(prompt_split[0] + \"### Answer:\\n\")[\"input_ids\"]  # Tokenize prompt only\n",
    "\n",
    "    result = tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,           # Truncate to max_length\n",
    "        padding=\"max_length\",      # Pad to max_length\n",
    "        max_length=384,            # Set max sequence length\n",
    "        return_tensors=None,       # Return as lists, not tensors\n",
    "    )\n",
    "\n",
    "    labels = [-100] * len(prompt_ids) + result[\"input_ids\"][len(prompt_ids):]  # Mask prompt tokens\n",
    "    labels = labels[:384] + [-100] * max(0, 384 - len(labels))                 # Pad/truncate labels to 384\n",
    "\n",
    "    result[\"labels\"] = labels  # Attach labels to result\n",
    "    return result              # Return tokenized dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "om3AOO3bVC-C"
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = formatted_dataset.map(tokenize, batched=False, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rr6-gpMP8XDs"
   },
   "source": [
    "## Step 6: Splitting the Tokenized Dataset into Train and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tf3wwWI78dK3"
   },
   "outputs": [],
   "source": [
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OE_81TL08fh4"
   },
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    \"train\": split_dataset[\"train\"],\n",
    "    \"validation\": split_dataset[\"test\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749782636706,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "RcTfndu28hDA",
    "outputId": "24d53964-1a68-47d0-b0bf-89bd56f3d768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 630\n",
      "Validation examples: 70\n"
     ]
    }
   ],
   "source": [
    "print(\"Training examples:\", len(dataset_dict[\"train\"]))\n",
    "print(\"Validation examples:\", len(dataset_dict[\"validation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1749782701228,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "85cOP5vbyaze",
    "outputId": "6be4f4ab-82e5-4299-d1e5-e39ae2df73c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|begin_of_text|>### Question:\n",
      "Is there any evidence of disease in the X-ray?\n",
      "\n",
      "### Answer:\n",
      "1. Severe emphysema. 2. Irregular, pleural-parenchymal opacity in left upper lobe. This may irregular pleural-parenchymal scarring, however, recommend comparison with more remote outside imaging, if available to determine long-term stability. If none are available, recommend short-term [REDACTED] in 3 to 4 months. Evaluation of coronal and sagittal reformatted images from the outside study would also be helpful. These were not [REDACTED] available at the outside institution. Malignancy cannot be confidently excluded on the available images\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "print(tokenizer.decode(tokenized_dataset[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6OITdrchLS5j"
   },
   "outputs": [],
   "source": [
    "# Decode the label sequence, replacing masked tokens (-100) with the pad token for readability\n",
    "print(tokenizer.decode([t if t != -100 else tokenizer.pad_token_id for t in tokenized_dataset[0][\"labels\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNIhRVmx9bdx"
   },
   "source": [
    "## Step 7: Saving the Tokenized Dataset to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QQjRX8p9KOq"
   },
   "outputs": [],
   "source": [
    "save_path = \"./data/tokenized_dataset\"\n",
    "\n",
    "dataset_dict.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxkZ3Unc9k5K"
   },
   "source": [
    "## Step 8: Verifying the Saved Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKPy2aCN9K6K"
   },
   "outputs": [],
   "source": [
    "# Path to the saved tokenized dataset\n",
    "load_path = \"file://./data/tokenized_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8y_5zOrRS_KR"
   },
   "outputs": [],
   "source": [
    "# Load the dataset from disk\n",
    "loaded_dataset = load_from_disk(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1749784832682,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "Rss9KpnC9tyJ",
    "outputId": "94fb40e8-5ffc-49e6-c636-0fd2c814492f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128000, 14711, 16225, 512, 861, 279, 3682, 73833, 94257, 14955, 304, 420, 2217, 382, 14711, 22559, 512, 2822, 30883, 73151, 454, 360, 55892, 1920, 26, 23900, 11, 4325, 18251, 65324, 296, 1123, 269, 94257, 67861, 42743, 64785, 79212, 488, 13], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128000, 14711, 16225, 512, 861, 279, 3682, 73833, 94257, 14955, 304, 420, 2217, 382, 14711, 22559, 512, 2822, 30883, 73151, 454, 360, 55892, 1920, 26, 23900, 11, 4325, 18251, 65324, 296, 1123, 269, 94257, 67861, 42743, 64785, 79212, 488, 13]}\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: view one example\n",
    "print(loaded_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1749785497990,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "tUC2YUxMV3Dy",
    "outputId": "fd5bab14-34bc-4e80-afcd-6694f513f2d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(len(loaded_dataset[\"train\"]))\n",
    "print(len(loaded_dataset[\"validation\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SldtfTjcSqAH"
   },
   "source": [
    "## Step 9: Fix Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7151,
     "status": "ok",
     "timestamp": 1749969290144,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "L6RnXxLVSuCu"
   },
   "outputs": [],
   "source": [
    "!pip install nbformat --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749969290153,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "dtJOMWKzS3uP"
   },
   "outputs": [],
   "source": [
    "import nbformat\n",
    "import os\n",
    "from google.colab import drive, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1zjKYzNS5rf"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2853,
     "status": "ok",
     "timestamp": 1749969311739,
     "user": {
      "displayName": "Samyak Shrestha (Caesar)",
      "userId": "13083503381857072620"
     },
     "user_tz": 300
    },
    "id": "JXphWaFuS7kk",
    "outputId": "051284e5-7c02-4c04-a780-29279945671c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10_tokenization.ipynb',\n",
       " '.gitkeep',\n",
       " '00_colab_setup.ipynb',\n",
       " '01_bootstrap.ipynb',\n",
       " '02_preprocessing.ipynb',\n",
       " '04_text_embedding_faiss_indexing.ipynb',\n",
       " '03_image_embedding_faiss_indexing.ipynb',\n",
       " '05_iu_xray_processing.ipynb',\n",
       " '06_generate_qa_pairs.ipynb',\n",
       " '08_finetune_biogpt_lora_run2.ipynb',\n",
       " '09_llama3_zero_shot_eval.ipynb',\n",
       " '07_finetune_biogpt_lora.ipynb',\n",
       " 'Copy of 10_tokenization.ipynb',\n",
       " '12_llama3_finetuned_eval.ipynb',\n",
       " '11_finetune_llama3.2_lora.ipynb',\n",
       " '10_tokenization_fixed.ipynb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the notebook directory to confirm the file exists\n",
    "os.listdir(\"/content/drive/MyDrive/multimodal-xray-agent/notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yjv672jxS9qr"
   },
   "outputs": [],
   "source": [
    "notebook_path = \"/content/drive/MyDrive/multimodal-xray-agent/notebooks/10_tokenization.ipynb\"\n",
    "\n",
    "with open(notebook_path, \"r\") as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "if \"widgets\" in nb.metadata:\n",
    "    del nb.metadata[\"widgets\"]\n",
    "\n",
    "with open(notebook_path, \"w\") as f:\n",
    "    nbformat.write(nb, f)\n",
    "\n",
    "print(\"Notebook fixed and saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP5TZUGfnO80obMoZdc25n7",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
